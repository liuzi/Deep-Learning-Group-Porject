{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"./dog_breeds/all/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial Imports"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport shutil\nfrom glob import glob \n\nfrom sklearn.utils import shuffle \nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\n## Specify a GPU\nimport os","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '../input/'\nmy_dir = '../input/dog_breeds/'\ntrain_folder = os.path.join(my_dir,'train')\nvalid_folder = os.path.join(my_dir,'valid')\ntest_folder = os.path.join(my_dir,'test')\n\n# train_folder = os.path.join(base_dir,'base_dir/train')\n# valid_folder = os.path.join(base_dir,'base_dir/valid')\n# test_folder = os.path.join(base_dir,'base_dir/test')\nval_file, train_file, test_file= [os.path.join(\"../input/dog-breeds\", name) \n                                          for name in os.listdir(\"../input/dog-breeds/\")]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(train_file)\ndf_val = pd.read_csv(val_file)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(test_file)\n# df_data = df.merge(labels, on = \"id\")\ndf_test.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"    breed_id                     breed                   id\n0  n02091032         Italian_greyhound  n02091032_10352.jpg\n1  n02099849  Chesapeake_Bay_retriever   n02099849_1997.jpg\n2  n02100583                    vizsla  n02100583_12639.jpg\n3  n02112137                      chow   n02112137_2664.jpg\n4  n02105855         Shetland_sheepdog  n02105855_11876.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>breed_id</th>\n      <th>breed</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n02091032</td>\n      <td>Italian_greyhound</td>\n      <td>n02091032_10352.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02099849</td>\n      <td>Chesapeake_Bay_retriever</td>\n      <td>n02099849_1997.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02100583</td>\n      <td>vizsla</td>\n      <td>n02100583_12639.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02112137</td>\n      <td>chow</td>\n      <td>n02112137_2664.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02105855</td>\n      <td>Shetland_sheepdog</td>\n      <td>n02105855_11876.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Only run for the first time: split training data into training and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs(os.path.join(my_dir, \"all/\"))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = df_train['breed']\n\ntrain_folder = os.path.join(my_dir,'train')\nvalid_folder = os.path.join(my_dir,'valid')\ntest_folder = os.path.join(my_dir,'test')\nfor fold in [train_folder, valid_folder, test_folder]:\n    for subf in train_y.unique():\n        os.makedirs(os.path.join(fold, subf))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"origin_data_dir =  os.path.join(my_dir, \"all/\")\ndf_train.set_index('id', inplace=True)\ndf_val.set_index('id', inplace=True)\ndf_test.set_index('id', inplace=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"origin_path = '../input/stanford-dogs-dataset/images/Images/'\nfor breed in os.listdir(origin_path):\n    for file in glob(os.path.join(origin_path,breed,'*.jpg')):\n        shutil.copyfile(file, os.path.join(origin_data_dir, file.split('/')[-1:][0]))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in df_train.index.values:\n    breed = str(df_train.loc[image,'breed']) # get the label for a certain image\n    src = os.path.join(origin_data_dir, image)\n    dst = os.path.join(train_folder, breed, image)\n    shutil.copyfile(src, dst)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in df_test.index.values:\n    breed = str(df_test.loc[image,'breed']) # get the label for a certain image\n    src = os.path.join(origin_data_dir, image)\n    dst = os.path.join(test_folder, breed, image)\n    shutil.copyfile(src, dst)\nfor image in df_val.index.values:\n    breed = str(df_val.loc[image,'breed']) # get the label for a certain image\n    src = os.path.join(origin_data_dir, image)\n    dst = os.path.join(valid_folder, breed, image)\n    shutil.copyfile(src, dst)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 299\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\nnum_test_samples = len(df_test)\n\ntrain_batch_size = 32\nval_batch_size = 32\ntest_batch_size = 32\nprint(\"Num of train samples: %d\" % num_train_samples)\nprint(\"Num of validation samples: %d\" % num_val_samples)\nprint(\"Num of test samples: %d\" % num_test_samples)\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\ntest_steps = np.ceil(num_test_samples / test_batch_size)\nprint(\"train_steps: %d\" % train_steps)\nprint(\"val_steps: %d\" % val_steps)\nprint(\"test_steps: %d\" % test_steps)","execution_count":12,"outputs":[{"output_type":"stream","text":"Num of train samples: 13171\nNum of validation samples: 3293\nNum of test samples: 4116\ntrain_steps: 412\nval_steps: 103\ntest_steps: 129\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n## Noramlize RGB values\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    # preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n    horizontal_flip=True,\n    vertical_flip=True)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = datagen.flow_from_directory(train_folder,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_folder,\n                                      target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                      batch_size=val_batch_size,\n                                      class_mode='categorical')\n\ntest_gen = datagen.flow_from_directory(test_folder,\n                                       target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                       batch_size=test_batch_size,\n                                       class_mode='categorical',\n                                       shuffle=False)","execution_count":14,"outputs":[{"output_type":"stream","text":"Found 13171 images belonging to 120 classes.\nFound 3293 images belonging to 120 classes.\nFound 4116 images belonging to 120 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## InceptionResNetV2 Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## InceptionResNetV2\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Sequential, Model\nfrom keras import layers\nfrom keras.layers import Concatenate, BatchNormalization, Flatten, Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n\nIMG_SIZE = (IMAGE_SIZE, IMAGE_SIZE)\nIN_SHAPE = (*IMG_SIZE, 3)\n\ndropout_dense=0.5\n\nconv_base = InceptionResNetV2(\n    weights='imagenet',\n    include_top=False,\n    input_shape=IN_SHAPE\n)\n\nmodel = Sequential()\nmodel.add(conv_base)\n## Version1\n# model.add(GlobalAveragePooling2D())\n# model.add(layers.Dense(1024, activation = \"relu\"))\n# model.add(layers.Dense(120, activation = \"softmax\"))\n\n# #Version 2 \n# model.add(GlobalAveragePooling2D())\n# model.add(layers.Dense(1024))\n# model.add(BatchNormalization())\n# model.add(Activation(\"relu\"))\n# model.add(layers.Dense(120, activation = \"softmax\"))\n\n\n# Version 3\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.001))\nmodel.add(GlobalMaxPooling2D())\n#model.add(layers.Dense(120, activation = \"sigmoid\"))\nmodel.add(layers.Dense(512, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.001))\nmodel.add(layers.Dense(120, activation = \"softmax\"))\n\n## Version 4\n# model.add(Flatten())\n# model.add(Dropout(0.001))\n# model.add(layers.Dense(120, activation = \"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.001))\n# model.add(layers.Dense(120, activation = \"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.001))\n# model.add(layers.Dense(120, activation = \"softmax\"))\n\n\n# conv_base.summary()\nconv_base.Trainable=True\n\nfrom keras import optimizers\n\n# conv_base.trainable = False\nmodel.compile(optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics=[\"accuracy\"])\n# model.load_weights('../input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')","execution_count":15,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219062272/219055592 [==============================] - 3s 0us/step\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Train inception_resnet model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nh5_path = \"inception_resnet_v2_relu_softmax_10.h5\"\ncheckpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nearlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1,restore_best_weights=True)\nreducel = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr = 0.000000001)\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                              validation_data=val_gen, validation_steps=val_steps,\n                              epochs=20,\n                              callbacks=[reducel, checkpoint])","execution_count":16,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/20\n412/412 [==============================] - 394s 956ms/step - loss: 1.8311 - acc: 0.5758 - val_loss: 1.1436 - val_acc: 0.6985\n\nEpoch 00001: val_acc improved from -inf to 0.69845, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 2/20\n412/412 [==============================] - 320s 777ms/step - loss: 0.7959 - acc: 0.7710 - val_loss: 0.9274 - val_acc: 0.7419\n\nEpoch 00002: val_acc improved from 0.69845 to 0.74188, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 3/20\n412/412 [==============================] - 320s 778ms/step - loss: 0.5209 - acc: 0.8425 - val_loss: 0.8627 - val_acc: 0.7586\n\nEpoch 00003: val_acc improved from 0.74188 to 0.75858, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 4/20\n412/412 [==============================] - 320s 777ms/step - loss: 0.3723 - acc: 0.8886 - val_loss: 0.9780 - val_acc: 0.7385\n\nEpoch 00004: val_acc did not improve from 0.75858\nEpoch 5/20\n412/412 [==============================] - 320s 777ms/step - loss: 0.2662 - acc: 0.9221 - val_loss: 0.9460 - val_acc: 0.7522\n\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 00005: val_acc did not improve from 0.75858\nEpoch 6/20\n412/412 [==============================] - 329s 798ms/step - loss: 0.1317 - acc: 0.9639 - val_loss: 0.7949 - val_acc: 0.7929\n\nEpoch 00006: val_acc improved from 0.75858 to 0.79289, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 7/20\n412/412 [==============================] - 329s 799ms/step - loss: 0.0848 - acc: 0.9768 - val_loss: 0.8655 - val_acc: 0.7865\n\nEpoch 00007: val_acc did not improve from 0.79289\nEpoch 8/20\n412/412 [==============================] - 329s 798ms/step - loss: 0.0620 - acc: 0.9846 - val_loss: 0.8052 - val_acc: 0.7923\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 00008: val_acc did not improve from 0.79289\nEpoch 9/20\n412/412 [==============================] - 328s 797ms/step - loss: 0.0389 - acc: 0.9908 - val_loss: 0.7867 - val_acc: 0.8132\n\nEpoch 00009: val_acc improved from 0.79289 to 0.81324, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 10/20\n412/412 [==============================] - 328s 796ms/step - loss: 0.0300 - acc: 0.9929 - val_loss: 0.8219 - val_acc: 0.8011\n\nEpoch 00010: val_acc did not improve from 0.81324\nEpoch 11/20\n412/412 [==============================] - 327s 795ms/step - loss: 0.0269 - acc: 0.9930 - val_loss: 0.8316 - val_acc: 0.8047\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\nEpoch 00011: val_acc did not improve from 0.81324\nEpoch 12/20\n412/412 [==============================] - 328s 797ms/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.7936 - val_acc: 0.8114\n\nEpoch 00012: val_acc did not improve from 0.81324\nEpoch 13/20\n412/412 [==============================] - 328s 796ms/step - loss: 0.0171 - acc: 0.9968 - val_loss: 0.7700 - val_acc: 0.8148\n\nEpoch 00013: val_acc improved from 0.81324 to 0.81476, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 14/20\n412/412 [==============================] - 328s 796ms/step - loss: 0.0144 - acc: 0.9972 - val_loss: 0.7911 - val_acc: 0.8142\n\nEpoch 00014: val_acc did not improve from 0.81476\nEpoch 15/20\n412/412 [==============================] - 328s 797ms/step - loss: 0.0116 - acc: 0.9980 - val_loss: 0.7863 - val_acc: 0.8163\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\nEpoch 00015: val_acc improved from 0.81476 to 0.81628, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 16/20\n412/412 [==============================] - 329s 799ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.8029 - val_acc: 0.8193\n\nEpoch 00016: val_acc improved from 0.81628 to 0.81931, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 17/20\n412/412 [==============================] - 331s 804ms/step - loss: 0.0093 - acc: 0.9981 - val_loss: 0.8027 - val_acc: 0.8172\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\nEpoch 00017: val_acc did not improve from 0.81931\nEpoch 18/20\n412/412 [==============================] - 333s 808ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.8026 - val_acc: 0.8220\n\nEpoch 00018: val_acc improved from 0.81931 to 0.82205, saving model to inception_resnet_v2_relu_softmax_10.h5\nEpoch 19/20\n412/412 [==============================] - 334s 810ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.8094 - val_acc: 0.8193\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\nEpoch 00019: val_acc did not improve from 0.82205\nEpoch 20/20\n412/412 [==============================] - 333s 808ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.8333 - val_acc: 0.8154\n\nEpoch 00020: val_acc did not improve from 0.82205\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy metric 1\nfrom keras.metrics import categorical_accuracy\nresult = model.evaluate_generator(test_gen,steps = test_steps)\nprint(model.metrics_names)\nprint(result)","execution_count":17,"outputs":[{"output_type":"stream","text":"['loss', 'acc']\n[0.7974663952001677, 0.8141399416909622]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}