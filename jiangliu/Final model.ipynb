{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob \n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "## Specify a GPU\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/data/liu/dog_breeds/'\n",
    "train_dir = '/data/liu/dog_breeds/train/'\n",
    "test_dir = '/data/liu/dog_breeds/test/'\n",
    "origin_data_dir = '/data/liu/all_images/'\n",
    "# train_folder = os.path.join(base_dir,'base_dir/train')\n",
    "# valid_folder = os.path.join(base_dir,'base_dir/valid')\n",
    "# test_folder = os.path.join(base_dir,'base_dir/test')\n",
    "train_folder = os.path.join(base_dir,'split_set/train')\n",
    "valid_folder = os.path.join(base_dir,'split_set/valid')\n",
    "test_folder = os.path.join(base_dir,'split_set/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(os.path.join(base_dir,\"test_label_name.csv\"))\n",
    "# df_train = pd.read_csv(os.path.join(base_dir,'df_train.csv'))\n",
    "# df_val = pd.read_csv(os.path.join(base_dir,'df_val.csv'))\n",
    "test_df = pd.read_csv(os.path.join(base_dir,\"df_test.csv\"))\n",
    "df_train = pd.read_csv(os.path.join(base_dir,'df_train.csv'))\n",
    "df_val = pd.read_csv(os.path.join(base_dir,'df_val.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only run for the first time: split training data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'path': glob(os.path.join(base_dir,'*.jpg'))})\n",
    "train_df = pd.read_csv(os.path.join(base_dir,\"train_label_name.csv\"))\n",
    "# df_data = df.merge(labels, on = \"id\")\n",
    "train_df .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed_id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02108000_2464.jpg</td>\n",
       "      <td>n02108000</td>\n",
       "      <td>EntleBucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02112350_9195.jpg</td>\n",
       "      <td>n02112350</td>\n",
       "      <td>keeshond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02088238_10072.jpg</td>\n",
       "      <td>n02088238</td>\n",
       "      <td>basset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n02091244_3631.jpg</td>\n",
       "      <td>n02091244</td>\n",
       "      <td>Ibizan_hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02095570_3534.jpg</td>\n",
       "      <td>n02095570</td>\n",
       "      <td>Lakeland_terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   breed_id             breed\n",
       "0   n02108000_2464.jpg  n02108000       EntleBucher\n",
       "1   n02112350_9195.jpg  n02112350          keeshond\n",
       "2  n02088238_10072.jpg  n02088238            basset\n",
       "3   n02091244_3631.jpg  n02091244      Ibizan_hound\n",
       "4   n02095570_3534.jpg  n02095570  Lakeland_terrier"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(base_dir,\"test_label_name.csv\"))\n",
    "# df_data = df.merge(labels, on = \"id\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split tarining data into training set and validation set\n",
    "train_y = train_df['breed']\n",
    "test_y = test_df['breed']\n",
    "df_train, df_val = train_test_split(train_df, test_size=0.10, random_state=101, stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save training set and validation set into files\n",
    "df_train.to_csv(os.path.join(base_dir,'df_train.csv'),index=False)\n",
    "df_val.to_csv(os.path.join(base_dir,'df_val.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed_id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n02106382_112.jpg</th>\n",
       "      <td>n02106382</td>\n",
       "      <td>Bouvier_des_Flandres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02096294_4535.jpg</th>\n",
       "      <td>n02096294</td>\n",
       "      <td>Australian_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02096294_6785.jpg</th>\n",
       "      <td>n02096294</td>\n",
       "      <td>Australian_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02107312_3673.jpg</th>\n",
       "      <td>n02107312</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02113023_7914.jpg</th>\n",
       "      <td>n02113023</td>\n",
       "      <td>Pembroke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     breed_id                 breed\n",
       "id                                                 \n",
       "n02106382_112.jpg   n02106382  Bouvier_des_Flandres\n",
       "n02096294_4535.jpg  n02096294    Australian_terrier\n",
       "n02096294_6785.jpg  n02096294    Australian_terrier\n",
       "n02107312_3673.jpg  n02107312    miniature_pinscher\n",
       "n02113023_7914.jpg  n02113023              Pembroke"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the id as the index in train_df\n",
    "train_df.set_index('id', inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed_id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n02108000_2464.jpg</th>\n",
       "      <td>n02108000</td>\n",
       "      <td>EntleBucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02112350_9195.jpg</th>\n",
       "      <td>n02112350</td>\n",
       "      <td>keeshond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02088238_10072.jpg</th>\n",
       "      <td>n02088238</td>\n",
       "      <td>basset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02091244_3631.jpg</th>\n",
       "      <td>n02091244</td>\n",
       "      <td>Ibizan_hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02095570_3534.jpg</th>\n",
       "      <td>n02095570</td>\n",
       "      <td>Lakeland_terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      breed_id             breed\n",
       "id                                              \n",
       "n02108000_2464.jpg   n02108000       EntleBucher\n",
       "n02112350_9195.jpg   n02112350          keeshond\n",
       "n02088238_10072.jpg  n02088238            basset\n",
       "n02091244_3631.jpg   n02091244      Ibizan_hound\n",
       "n02095570_3534.jpg   n02095570  Lakeland_terrier"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the id as the index in test_df\n",
    "test_df.set_index('id', inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder fistly\n",
    "train_y = pd.read_csv(os.path.join(base_dir,'all_dogs.csv'))['breed']\n",
    "\n",
    "train_folder = os.path.join(base_dir,'split_set/train')\n",
    "valid_folder = os.path.join(base_dir,'split_set/valid')\n",
    "test_folder = os.path.join(base_dir,'split_set/test')\n",
    "for fold in [train_folder, valid_folder, test_folder]:\n",
    "    for subf in train_y.unique():\n",
    "        os.makedirs(os.path.join(fold, subf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy images into new generated training and validation directory. src, dsg -> original path, destination path\n",
    "# df_train.set_index('id', inplace=True)\n",
    "# df_val.set_index('id', inplace=True)\n",
    "# test_df.set_index('id', inplace=True)\n",
    "\n",
    "for image in df_train.index.values:\n",
    "    breed = str(df_train.loc[image,'breed']) # get the label for a certain image\n",
    "    src = os.path.join(origin_data_dir, image)\n",
    "    dst = os.path.join(train_folder, breed, image)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "for image in df_val.index.values:\n",
    "    breed = str(df_val.loc[image,'breed']) # get the label for a certain image\n",
    "    src = os.path.join(origin_data_dir, image)\n",
    "    dst = os.path.join(valid_folder, breed, image)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy test images (breeds as folders' names)\n",
    "\n",
    "for image in test_df.index.values:\n",
    "    breed = str(test_df.loc[image,'breed']) # get the label for a certain image\n",
    "    src = os.path.join(origin_data_dir, image)\n",
    "    dst = os.path.join(test_folder, breed, image)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train samples: 13171\n",
      "Num of validation samples: 3293\n",
      "Num of test samples: 4116\n",
      "train_steps: 412\n",
      "val_steps: 103\n",
      "test_steps: 129\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 331\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "num_test_samples = len(test_df)\n",
    "\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "test_batch_size = 32\n",
    "print(\"Num of train samples: %d\" % num_train_samples)\n",
    "print(\"Num of validation samples: %d\" % num_val_samples)\n",
    "print(\"Num of test samples: %d\" % num_test_samples)\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "test_steps = np.ceil(num_test_samples / test_batch_size)\n",
    "print(\"train_steps: %d\" % train_steps)\n",
    "print(\"val_steps: %d\" % val_steps)\n",
    "print(\"test_steps: %d\" % test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "## Noramlize RGB values\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13171 images belonging to 120 classes.\n",
      "Found 3293 images belonging to 120 classes.\n",
      "Found 4116 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(train_folder,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_folder,\n",
    "                                      target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                      batch_size=val_batch_size,\n",
    "                                      class_mode='categorical')\n",
    "\n",
    "test_gen = datagen.flow_from_directory(test_folder,\n",
    "                                       target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                       batch_size=test_batch_size,\n",
    "                                       class_mode='categorical',\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionResNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Invalid keyword argument: %s', 'dropout')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-867b0b9d1c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIN_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/applications/inception_resnet_v2.py\u001b[0m in \u001b[0;36mInceptionResNetV2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mInceptionResNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minception_resnet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInceptionResNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras_applications/inception_resnet_v2.py\u001b[0m in \u001b[0;36mInceptionResNetV2\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \"\"\"\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_utils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_submodules_from_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras_applications/__init__.py\u001b[0m in \u001b[0;36mget_submodules_from_kwargs\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid keyword argument: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Invalid keyword argument: %s', 'dropout')"
     ]
    }
   ],
   "source": [
    "## InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Concatenate, BatchNormalization, Flatten, Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "\n",
    "IMG_SIZE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "IN_SHAPE = (*IMG_SIZE, 3)\n",
    "\n",
    "dropout_dense=0.5\n",
    "\n",
    "conv_base = InceptionResNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=IN_SHAPE\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# # model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "# model.add(layers.Dense(1024, activation = \"relu\"))\n",
    "# model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.001))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "#model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "model.add(layers.Dense(512, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.001))\n",
    "model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "# conv_base.summary()\n",
    "conv_base.Trainable=True\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# conv_base.trainable = False\n",
    "model.compile(optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "412/412 [==============================] - 364s 884ms/step - loss: 0.2037 - acc: 0.9355 - val_loss: 1.2187 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69967, saving model to inception_resnet_v2_relu_softmax_10.h5\n",
      "Epoch 2/10\n",
      "412/412 [==============================] - 365s 887ms/step - loss: 0.1585 - acc: 0.9503 - val_loss: 1.2709 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69967 to 0.70544, saving model to inception_resnet_v2_relu_softmax_10.h5\n",
      "Epoch 3/10\n",
      "412/412 [==============================] - 361s 876ms/step - loss: 0.1356 - acc: 0.9582 - val_loss: 1.3429 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70544\n",
      "Epoch 4/10\n",
      "412/412 [==============================] - 364s 885ms/step - loss: 0.0798 - acc: 0.9773 - val_loss: 1.2218 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70544 to 0.72578, saving model to inception_resnet_v2_relu_softmax_10.h5\n",
      "Epoch 5/10\n",
      "412/412 [==============================] - 383s 930ms/step - loss: 0.0654 - acc: 0.9802 - val_loss: 1.2478 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72578\n",
      "Epoch 6/10\n",
      "412/412 [==============================] - 411s 997ms/step - loss: 0.0445 - acc: 0.9879 - val_loss: 1.2691 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72578\n",
      "Epoch 7/10\n",
      "412/412 [==============================] - 395s 959ms/step - loss: 0.0325 - acc: 0.9922 - val_loss: 1.2664 - val_acc: 0.7346\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72578 to 0.73459, saving model to inception_resnet_v2_relu_softmax_10.h5\n",
      "Epoch 8/10\n",
      "412/412 [==============================] - 396s 962ms/step - loss: 0.0298 - acc: 0.9916 - val_loss: 1.2621 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73459\n",
      "Epoch 9/10\n",
      "412/412 [==============================] - 395s 958ms/step - loss: 0.0245 - acc: 0.9938 - val_loss: 1.2369 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73459\n",
      "Epoch 10/10\n",
      "412/412 [==============================] - 385s 935ms/step - loss: 0.0203 - acc: 0.9950 - val_loss: 1.2950 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.73459\n"
     ]
    }
   ],
   "source": [
    "## Train inception_resnet model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "h5_path = \"inception_resnet_v2_relu_softmax_10.h5\"\n",
    "checkpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1,restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr = 0.000000001)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                              validation_data=val_gen, validation_steps=val_steps,\n",
    "                              epochs=10,\n",
    "                              callbacks=[reducel, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LARGEFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## LARGEFILE\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Concatenate, BatchNormalization, Flatten, Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "\n",
    "IMG_SIZE=331\n",
    "IMG_SIZE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "IN_SHAPE = (*IMG_SIZE, 3)\n",
    "\n",
    "\n",
    "conv_base= NASNetLarge(input_shape=IN_SHAPE, \n",
    "                       include_top=False, \n",
    "                       weights='imagenet')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.001))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "#model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "model.add(layers.Dense(512, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.001))\n",
    "model.add(layers.Dense(120, activation = \"sigmoid\"))\n",
    "\n",
    "# conv_base.summary()\n",
    "conv_base.Trainable=True\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# conv_base.trainable = False\n",
    "model.compile(optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,42,42,168]\n\t [[Node: NASNet/separable_conv_2_normal_right1_4/separable_conv2d = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NASNet/separable_conv_2_normal_right1_4/separable_conv2d/depthwise, normal_A_block_4/block_1/separable_conv_block_normal_right1_4/separable_conv_2_normal_right1_4/pointwise_kernel/read)]]\n\t [[Node: metrics/acc/Mean/_20299 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_94703_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'NASNet/separable_conv_2_normal_right1_4/separable_conv2d', defined at:\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-5a2d8b2c6ec1>\", line 19, in <module>\n    model.add(conv_base)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/sequential.py\", line 165, in add\n    layer(x)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/network.py\", line 564, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/network.py\", line 721, in run_internal_graph\n    layer.call(computed_tensor, **kwargs))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 1386, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3811, in separable_conv2d\n    data_format=tf_data_format)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py\", line 497, in separable_conv2d\n    name=name)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,42,42,168]\n\t [[Node: NASNet/separable_conv_2_normal_right1_4/separable_conv2d = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NASNet/separable_conv_2_normal_right1_4/separable_conv2d/depthwise, normal_A_block_4/block_1/separable_conv_block_normal_right1_4/separable_conv_2_normal_right1_4/pointwise_kernel/read)]]\n\t [[Node: metrics/acc/Mean/_20299 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_94703_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,42,42,168]\n\t [[Node: NASNet/separable_conv_2_normal_right1_4/separable_conv2d = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NASNet/separable_conv_2_normal_right1_4/separable_conv2d/depthwise, normal_A_block_4/block_1/separable_conv_block_normal_right1_4/separable_conv_2_normal_right1_4/pointwise_kernel/read)]]\n\t [[Node: metrics/acc/Mean/_20299 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_94703_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-84e666d18c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                               callbacks=[reducel, checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,42,42,168]\n\t [[Node: NASNet/separable_conv_2_normal_right1_4/separable_conv2d = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NASNet/separable_conv_2_normal_right1_4/separable_conv2d/depthwise, normal_A_block_4/block_1/separable_conv_block_normal_right1_4/separable_conv_2_normal_right1_4/pointwise_kernel/read)]]\n\t [[Node: metrics/acc/Mean/_20299 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_94703_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'NASNet/separable_conv_2_normal_right1_4/separable_conv2d', defined at:\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-5a2d8b2c6ec1>\", line 19, in <module>\n    model.add(conv_base)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/sequential.py\", line 165, in add\n    layer(x)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/network.py\", line 564, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/network.py\", line 721, in run_internal_graph\n    layer.call(computed_tensor, **kwargs))\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 1386, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3811, in separable_conv2d\n    data_format=tf_data_format)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py\", line 497, in separable_conv2d\n    name=name)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/liu/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,42,42,168]\n\t [[Node: NASNet/separable_conv_2_normal_right1_4/separable_conv2d = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NASNet/separable_conv_2_normal_right1_4/separable_conv2d/depthwise, normal_A_block_4/block_1/separable_conv_block_normal_right1_4/separable_conv_2_normal_right1_4/pointwise_kernel/read)]]\n\t [[Node: metrics/acc/Mean/_20299 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_94703_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "## Train inception_resnet model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "h5_path = \"NASNetLarge_relu.h5\"\n",
    "checkpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1,restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr = 0.000000001)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                              validation_data=val_gen, validation_steps=val_steps,\n",
    "                              epochs=10,\n",
    "                              callbacks=[reducel, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.199461695056615, 0.7429543245290529]\n"
     ]
    }
   ],
   "source": [
    "# accuracy metric 1\n",
    "from keras.metrics import categorical_accuracy\n",
    "result = model.evaluate_generator(test_gen,steps = test_steps)\n",
    "print(model.metrics_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738581146744412"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy metric 2\n",
    "## return the probability of each class\n",
    "# probs_120 = model.predict_generator(test_gen,steps = test_steps,verbose=1)\n",
    "# y_pred = np.argmax(probs_120,axis=1)\n",
    "# accuracy_score(test_gen.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(test_gen.classes, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=range(0,120), yticklabels=range(0,120))\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -c 'import keras; print(keras.__version__)'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
